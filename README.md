# NYC_Property_Sales_Project
Ссылка на файл в Loginom: https://drive.google.com/file/d/1ti9jbvFzeePyX_mS0-bnHXk3MHLVmtj9/view?usp=sharing
Ссылка на сырые данные: https://drive.google.com/file/d/1gAVHATxVjGM3cjTCZgqoB2bm2LkW4Faw/view?usp=sharing
Ссылка на источник данных в Kaggle: NYC Property Sales | Kaggle
Ссылка на блокнот Google Colab: https://colab.research.google.com/drive/1hr-byEVNy40YcpzLe96l7yd606apa9CO?usp=sharing
Ссылка на преобразованные данные: https://drive.google.com/file/d/14cqy5ZChH5zYAMa0EVZ-KufiBzdbxZME/view?usp=sharing
Ссылка на дэшборд в Yandex Datalens: 
https://datalens.yandex/qpo5d01m65maf
1.	О КЕЙСЕ
1.1.	Контекст
Найденный мной набор данных представляет собой запись о каждом здании/элементе недвижимости/строительной единице (квартире и т.д.), проданых на рынке недвижимости Нью-Йорка за 12-месячный период.

1.2.	Содержание
Этот набор данных содержит местоположение, адрес, тип, цену продажи и дату продажи проданных единиц недвижимости. Подробнее о некоторых полях:
•	Район: цифровой код района, в котором расположен объект недвижимости; по порядку это Манхэттен (1), Бронкс (2), Бруклин (3), Куинс (4) и Стейтен-Айленд (5).
•	Квартал/участок: Сочетание района, квартала и участка образует уникальный ключ к недвижимости в Нью-Йорке. 
•	Класс здания: тип здания в различные моменты времени. 

2.	ЦЕЛЬ И ЗАДАЧИ РАБОТЫ
В данной практической работе я должен был выполнить следующие задачи:
1.	Извлечь сырые данные из источника и провести их консолидацию, первичную обработку (препроцессинг),   очистку, трансформацию по типу Extract-Load-Transform в платформе Loginom.  В добавок в этому необходимо было произвести обогащение данных кейса с помощью ABC-XYZ анализа, а также обучить и оценить по метрикам качества модель машинного обучения и экспортировать обработанные данные в файл формата CSV.
2.	Далее требовалось в облачной среде для работы с кодом “Google Colab” над подготовленными данными провести EDA, обучить модель машинного обучения с использованием любого фреймворка, провести прогнозирование ответа лучшей модели на новых данных и сравнить показатели с ранее полученными с помощью Loginom.
3.	В конечном счете я должен был импортировать подготовленный датасет в Yandex Datalens, построить дашборды, выявить инсайты, оформить истории (Story).
Цель работы – провести препроцессинг данных, обучить модель, предсказать целевую переменную и построить интерактивный отчет на преобразованных данных.

3.	ХОД РАБОТЫ
В целях первичного ознакомления с полученными из источника данными они были изначально загружены мной в Google BigQuery, просмотрены в блокноте Google Colab с помощью различных агрегирующих запросов SQL. Впоследствии данные были переведены в платформу Loginom, в которой посредством встроенных утилит был сконструктуирован своего рода Pipeline, производящий считывание данных, их первичную обработку, очистку и загрузку в файл CSV. Помимо этого, были устранены выбросы (значения, характерно отклоняющиеся от общей совокупности данных). Некоторые пропущенные и нулевые ячейки были заменены медианными значениями по их столбцу, некоторые – наиболее вероятным, некоторые были удалены для предотвращения искаженности данных и внесения неясностей, которые впоследвствии могли повлиять на показатели предсказания модели машинного обучения. Для получения и оценки предварительных результатов обработанные данные были отображены в форматах таблиц и статистик на разных этапах процессинга с помощью разных визуализаторов.
Была произведена индексация каждого элемента недвижимости путем ABC/XYZ‑анализа. Исходя из рассчитанной кумулятивной суммы за жилье для каждого района и количества элементов недвижимости были выявлены наиболее выгодные и благоприятные для проживания районы. Каждому району был присвоен иденкс качества проживания: AX, AY, AZ, BX, BY, BZ, CX, CY, CZ, отсортированный в порядке от наиболее дорогих районов с разнообразием мест для проживания до дешевых районов с нехваткой жилых помещений соотвественно. Так, например, район с индексом уровня проживания AZ считается дорогим, но с дефицитом свободной недвижимости, в то время как район CX является дешевым, однако мест для проживания в нем предостаточно на момент предоставления данных.
Для построения модели машинного обучения была создана искусственная целевая переменная, рассчитанная по нескольким критериям – In-Demand, отображающая, является ли текущее место жительства востребованным среди людей, желающих выкупить недвижимость. Переменная принимает булевое значение – 0/1. 0 – недвижимость не пользуется особым спросом, 1 – считается желанным на рынке недвижимости.
Следующим этапом была построена модель машинного обучения для решения задачи классификации – Логистическая регрессия. На вход были переданы информативные и значимые признаки из подготовленного датасета, на выход – переменная-таргет -  In-Demand. Результаты предсказания и высчитанные коэффициенты были записаны в отдельных выходные текстовые файлы формата CSV.
Впоследствии данные были переведены на Google Colab, где они также подвергались преобразованию и подготовке признаков для работы с моделями машинного обучения. Были удалены неинформативные признаки, изменены типы и доработаны пропущенные (нулевые) значения. Путем преобразования категориальных признаков в числовые были созданы индикаторы признаков. Для исключения мультиколлинеарности признаков были удалены признаки, ее вызывающие. 
Exploratory Data Analysis можно наблюдать в файле, предоставленном по ссылку выше. Приведены описания построенных графиков и некоторые статистические характеристики.
Следующим шагом была проведена транспортировка подготовленных данных в Yandex Datalens. Первоначально были построены чарты, отображающие статистические показатели определенных признаков, их изменения с течением времени и относительно района проживания, были подсчитаны агрегирующие измерения, основанные на показателях для более содержательных отображений чартов. Далее созданные чарты были скомпанованы и переведены в дашборд, состоящих из трех вкладок, каждая из которых представляет визуальную интерактивную статистическую информацию по датасету. 
 
На первой вкладке проделанной мной визуальной отчетности в Yandex Datalens представлены цены на недвижимость в каждом городском округе. Из диаграммы с областями и накоплением видно, что наиболее дорогим районом является 5 – Стейтен-Айленд со средней стоимостью жилья 170 574$. На вкладке также представлены pie chart и таблица для альтернативного отображения. Внедрен селектор, позволяющий фильтровать данные на вкладке по округам.
 
На следующей вкладке можно наблюдать количество жилых помещений в каждом округе с течением времени. Таким образом, проанализировав, можно заметить, что в 2007 году был наибольший спрос на элементы недвижимости, по большей части во 2 городском округе – Бронксе, ведь Бронкс находится вблизи городских центров, предлагает разнообразные варианты жилья, включая квартиры, дома и кооперативы. В сравнении с некоторыми другими районами Нью-Йорка, цены на жилье в Бронксе могут быть более доступными. Что касается наиболее загруженным округом с наибольшим количеством апартаментов, то это 1 – Манхэттен. 
 
На третьей вкладке отображена стоимость недвижимости в Нью-Йорке на протяжении нескольких лет (ХХ-ХХI века). Так, наибольшую суммарную стоимость за место жительства горожане ощутили в 1990 году – почти 3 миллиарда долларов. Вероятно, это обуславливается тем, что в 1980-х годах в Нью-Йорке цены на жилье были высокими из-за ряда факторов, включая рост популяции, ограниченную доступность земли и строительных ресурсов, а также высокий спрос на жилье в городе. В добавок к этому произошли экономические и социальные изменения, включая финансовый кризис и проблемы с общественной безопасностью. Это могло повлиять на рынок недвижимости и привести к увеличению цен на жилье.
Манхэттен оставался самым востребованным округом с наиболее дорогой стоимостью проживания.

4.	ВЫВОД
В результате данной проектной работы можно сделать вывод, что показатели модели классификации машинного обучения, измеренные в платформе Loginom и в среде Google Colab, практически не отличаются друг от друга. Значения accuracy составили 0.984 в платформе Loginom и 0.988 в среде Google Colab соответственно. Это говорит о том, что модель успешно обучена и показывает стабильные результаты независимо от выбранной среды для обучения. Впервые поработав на платформе Loginom, я освоил многие ее утилиты и средства манипуляции с данными, получил достаточно практических знаний. В перспективе будет проводиться работа над ошибками, некоторыми неясностями, которые я выявил для себя в этой работе.
